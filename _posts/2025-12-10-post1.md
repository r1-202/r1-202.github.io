---
title: "Hello World"
date: 2025-12-10
categories: [first post]
tags: [first post]
---

# Pardon the Cliche Title

Pardon the cliche title. This is my first blog post.

This blog will be dedicated to my journey trying to learn about computer graphics and ASIC/FPGA programming (for 
the purpose of accelerating computer graphics-related operations). I will use this post to provide a bit of an 
introduction about myself that is relevant to why I am trying to learn computer graphics and IC design.

My name is Kassem Hmady, and I have recently graduated with a bachelor's in 
Electrical and Telecommunications Engineering (commonly known as CCE) and Mathematics
from the Lebanese University. I am currently pursuing a master's degree in applied mathematics 
at the American University of Beirut (AUB), and I really love mathematics. 

Computer graphics 
caught my attention when I was trying to see how video games are able to mimic reality in 
form and function, and that lead me down a rabbit-hole of trying to learn about game 
engine development and a whole lot of mathematics and physics. I have been hooked since. 
Now the IC part is something I started thinking about when I enrolled in a training program this 
past summer that taught the attendees digital and analogue IC design fundamentals. It was 
my first contact with Verilog, a lovely hardware description language which introduced me 
to a whole new type of programming that really changed the way I viewed computational systems. They were 
not sequential anymore as the code I write in C++ implies, but rather are heavily parallel and rely on 
complex physics to guarantee performance and correctness. C++ was a simplified way of interacting with 
these systems, but building one with verilog was a different experience.

This brings us to the present day. I now have enough free time to continue my journey into the vast world 
of computer graphics, specifically the mathematics and physics behind it, and throughout I hope 
to be able to design hardware components to support the critical operations I need. This will largley 
be guided by the present literature on GPU architecture and design. At the end of the day GPUs 
are CPUs' close nighbours that started out as optimizations of CPUs that are more suitable to 
graphical applications. GPUs are now transforming the way we compute especially with the rising 
popularity of AI and the need of more parallelism, but the G in GPUs will always stand for Graphics.

Any comments, tips, suggestions, and job opportunities are more than welcome.
